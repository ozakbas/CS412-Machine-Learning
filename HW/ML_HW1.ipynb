{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_HW1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ozakbas/CS412-Machine-Learning/blob/main/HW/ML_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrzkxpZrCF6D"
      },
      "source": [
        "# CS 412 Machine Learning 2020 \n",
        "\n",
        "# Assignment 1\n",
        "\n",
        "100 pts\n",
        "\n",
        "## Goal \n",
        "\n",
        "The goal of this assignment \n",
        "\n",
        "*  Introduction to the machine learning experimental set up\n",
        "*  Gain experience with the Scikit library\n",
        "*  Gain experience with Decision tree and k-NN models\n",
        "\n",
        "## Dataset\n",
        "\n",
        "**Wine Quality Dataset** is a collection red and white wines with 12 attributes. The target variable is the 'quality' either 0 or 1\n",
        "\n",
        "\n",
        "## Task\n",
        "Build a decision tree and k-NN classifiers with the scikit-learn library function calls to **classify** the quality of wine as good (1) and bad (0)\n",
        "\n",
        "## Submission\n",
        "\n",
        "Follow the instructions at the end."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18kyKgy9LiZx"
      },
      "source": [
        "# 1) Initialize\n",
        "\n",
        "First, make a copy of this notebook in your drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTJUORO9CBNq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fc995d3-89e8-447e-f554-5cd539572db8"
      },
      "source": [
        "# Mount to your drive, in this way you can reach files that are in your drive\n",
        "# Run this cell\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtputkpVLt8H"
      },
      "source": [
        "# 2) Load Dataset\n",
        "To start working for your homework, take a copy of the folder, given in the below link to your own google drive. You find the train and test data under this folder.\n",
        "\n",
        "https://drive.google.com/drive/folders/1PC6M332CTdW-OOrgJ-1GU1F3UaRupka8?usp=sharing\n",
        "\n",
        "After copy the folder, copy the path of the train and test dataset to paste them in the below cell to load your data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB1Fur5APIjQ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train_df = pd.read_csv('/content/drive/My Drive/Recitation/winequality-train.csv')\n",
        "test_df = pd.read_csv('/content/drive/My Drive/Recitation/winequality-test.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rtcu1QMXMLBN"
      },
      "source": [
        "# 3) Understand the dataset\n",
        "\n",
        "You can use the fuctions that we saw in the recitations to understand the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjQj6XQNMd68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "6afb4a05-6d10-4edd-fd03-84b700386112"
      },
      "source": [
        "# print shape of the train and test sets\n",
        "print('Train shape: ', train_df.shape)\n",
        "print('Test shape: ', test_df.shape)\n",
        "\n",
        "# show random samples from the training data\n",
        "train_df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape:  (5198, 13)\n",
            "Test shape:  (1299, 13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>wine type</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.1</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.24</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.036</td>\n",
              "      <td>38.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>0.98980</td>\n",
              "      <td>3.29</td>\n",
              "      <td>0.42</td>\n",
              "      <td>12.4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.8</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.28</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.018</td>\n",
              "      <td>18.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.99260</td>\n",
              "      <td>2.97</td>\n",
              "      <td>0.35</td>\n",
              "      <td>10.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.1</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.30</td>\n",
              "      <td>6.3</td>\n",
              "      <td>0.039</td>\n",
              "      <td>47.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>0.99068</td>\n",
              "      <td>3.27</td>\n",
              "      <td>0.31</td>\n",
              "      <td>12.7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.8</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.38</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.040</td>\n",
              "      <td>39.0</td>\n",
              "      <td>148.0</td>\n",
              "      <td>0.99420</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.67</td>\n",
              "      <td>10.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11.5</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.48</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.077</td>\n",
              "      <td>8.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.99852</td>\n",
              "      <td>3.09</td>\n",
              "      <td>0.53</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  ...  alcohol  wine type  quality\n",
              "0            6.1              0.32         0.24  ...     12.4          0        1\n",
              "1            8.8              0.20         0.28  ...     10.4          0        0\n",
              "2            6.1              0.21         0.30  ...     12.7          0        0\n",
              "3            8.8              0.17         0.38  ...     10.2          0        0\n",
              "4           11.5              0.42         0.48  ...     11.0          1        0\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5B93dybOMqBF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa5a6b41-4271-45f3-c23c-619448468b9d"
      },
      "source": [
        "# print information about the datasets (Is there any missing value? or Categorical feature?)\n",
        "print(train_df.info())\n",
        "print(train_df.isnull().any())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5198 entries, 0 to 5197\n",
            "Data columns (total 13 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed acidity         5198 non-null   float64\n",
            " 1   volatile acidity      5198 non-null   float64\n",
            " 2   citric acid           5198 non-null   float64\n",
            " 3   residual sugar        5198 non-null   float64\n",
            " 4   chlorides             5198 non-null   float64\n",
            " 5   free sulfur dioxide   5198 non-null   float64\n",
            " 6   total sulfur dioxide  5198 non-null   float64\n",
            " 7   density               5198 non-null   float64\n",
            " 8   pH                    5198 non-null   float64\n",
            " 9   sulphates             5198 non-null   float64\n",
            " 10  alcohol               5198 non-null   float64\n",
            " 11  wine type             5198 non-null   int64  \n",
            " 12  quality               5198 non-null   int64  \n",
            "dtypes: float64(11), int64(2)\n",
            "memory usage: 528.0 KB\n",
            "None\n",
            "fixed acidity           False\n",
            "volatile acidity        False\n",
            "citric acid             False\n",
            "residual sugar          False\n",
            "chlorides               False\n",
            "free sulfur dioxide     False\n",
            "total sulfur dioxide    False\n",
            "density                 False\n",
            "pH                      False\n",
            "sulphates               False\n",
            "alcohol                 False\n",
            "wine type               False\n",
            "quality                 False\n",
            "dtype: bool\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAFQHAq8Mno1"
      },
      "source": [
        "# 4) Define train and test labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjW1ZNhONNCb"
      },
      "source": [
        "# make sure you remove the labels from datasets\n",
        "\n",
        "train_labels = train_df.pop('quality')\n",
        "test_labels = test_df.pop('quality')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fn3N4V_OlL_"
      },
      "source": [
        "# 5) FineTune Decision Tree hyper-parameters\n",
        "\n",
        "1-Splitting dataset into train and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJlxVMTnYTTg"
      },
      "source": [
        "# Split training data to 70% training and 30% validation, do not forget to use the random_state parameter\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(train_df, train_labels, test_size=0.3, random_state=12)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNm9SC9JYXN2"
      },
      "source": [
        "2- FineTune minimum sample split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfTLLotIO3WX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4823e99b-db76-4810-b014-38549dedefbb"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "min_samples_splits = range(2, 50)\n",
        "\n",
        "train_results = []\n",
        "val_results = []\n",
        "for min_samples_split in min_samples_splits:\n",
        "\n",
        "  # Fit the tree using the 70% portion of the training data\n",
        "  clf = DecisionTreeClassifier(min_samples_split=min_samples_split, random_state=2021)\n",
        "  clf.fit(x_train, y_train)\n",
        "  \n",
        "  # Evaluate on Training set\n",
        "  train_acc = clf.score(x_train, y_train)\n",
        "  train_results.append(train_acc)\n",
        "   \n",
        "  # Evaluate on Validation set\n",
        "  val_acc = clf.score(x_val, y_val)\n",
        "  val_results.append(val_acc)\n",
        "\n",
        "  print(\"min_sample_splits: {} train: {} val: {}\".format(min_samples_split, train_acc, val_acc))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "min_sample_splits: 2 train: 1.0 val: 0.8128205128205128\n",
            "min_sample_splits: 3 train: 0.9939527212754261 val: 0.8173076923076923\n",
            "min_sample_splits: 4 train: 0.9873556899395272 val: 0.8173076923076923\n",
            "min_sample_splits: 5 train: 0.9813084112149533 val: 0.8243589743589743\n",
            "min_sample_splits: 6 train: 0.9752611324903794 val: 0.8179487179487179\n",
            "min_sample_splits: 7 train: 0.9681143485431556 val: 0.8217948717948718\n",
            "min_sample_splits: 8 train: 0.9615173172072567 val: 0.823076923076923\n",
            "min_sample_splits: 9 train: 0.9565695437053326 val: 0.8153846153846154\n",
            "min_sample_splits: 10 train: 0.951346893897746 val: 0.8153846153846154\n",
            "min_sample_splits: 11 train: 0.945849367784497 val: 0.8147435897435897\n",
            "min_sample_splits: 12 train: 0.9414513468938978 val: 0.8032051282051282\n",
            "min_sample_splits: 13 train: 0.9384277075316108 val: 0.8102564102564103\n",
            "min_sample_splits: 14 train: 0.934304562946674 val: 0.808974358974359\n",
            "min_sample_splits: 15 train: 0.9315557998900494 val: 0.8153846153846154\n",
            "min_sample_splits: 16 train: 0.9307311709730621 val: 0.8121794871794872\n",
            "min_sample_splits: 17 train: 0.9312809235843871 val: 0.808974358974359\n",
            "min_sample_splits: 18 train: 0.9268829026937878 val: 0.8153846153846154\n",
            "min_sample_splits: 19 train: 0.9255085211654756 val: 0.8134615384615385\n",
            "min_sample_splits: 20 train: 0.922759758108851 val: 0.8153846153846154\n",
            "min_sample_splits: 21 train: 0.9205607476635514 val: 0.8166666666666667\n",
            "min_sample_splits: 22 train: 0.916712479384277 val: 0.8102564102564103\n",
            "min_sample_splits: 23 train: 0.9153380978559648 val: 0.8121794871794872\n",
            "min_sample_splits: 24 train: 0.9139637163276526 val: 0.8102564102564103\n",
            "min_sample_splits: 25 train: 0.9117647058823529 val: 0.8108974358974359\n",
            "min_sample_splits: 26 train: 0.9092908191313909 val: 0.8076923076923077\n",
            "min_sample_splits: 27 train: 0.9068169323804288 val: 0.8083333333333333\n",
            "min_sample_splits: 28 train: 0.9040681693238043 val: 0.808974358974359\n",
            "min_sample_splits: 29 train: 0.902693787795492 val: 0.8064102564102564\n",
            "min_sample_splits: 30 train: 0.8985706432105552 val: 0.8076923076923077\n",
            "min_sample_splits: 31 train: 0.8960967564595932 val: 0.8108974358974359\n",
            "min_sample_splits: 32 train: 0.8960967564595932 val: 0.8108974358974359\n",
            "min_sample_splits: 33 train: 0.8925233644859814 val: 0.8128205128205128\n",
            "min_sample_splits: 34 train: 0.8911489829576691 val: 0.8115384615384615\n",
            "min_sample_splits: 35 train: 0.8881253435953821 val: 0.8070512820512821\n",
            "min_sample_splits: 36 train: 0.8864760857614074 val: 0.8083333333333333\n",
            "min_sample_splits: 37 train: 0.8862012094557449 val: 0.8083333333333333\n",
            "min_sample_splits: 38 train: 0.88565145684442 val: 0.8083333333333333\n",
            "min_sample_splits: 39 train: 0.88565145684442 val: 0.8083333333333333\n",
            "min_sample_splits: 40 train: 0.8853765805387576 val: 0.8083333333333333\n",
            "min_sample_splits: 41 train: 0.8853765805387576 val: 0.8083333333333333\n",
            "min_sample_splits: 42 train: 0.8834524463991204 val: 0.8121794871794872\n",
            "min_sample_splits: 43 train: 0.882627817482133 val: 0.8108974358974359\n",
            "min_sample_splits: 44 train: 0.882627817482133 val: 0.8108974358974359\n",
            "min_sample_splits: 45 train: 0.882627817482133 val: 0.8108974358974359\n",
            "min_sample_splits: 46 train: 0.8820780648708081 val: 0.8115384615384615\n",
            "min_sample_splits: 47 train: 0.8820780648708081 val: 0.8115384615384615\n",
            "min_sample_splits: 48 train: 0.8809785596481583 val: 0.8173076923076923\n",
            "min_sample_splits: 49 train: 0.8793293018141837 val: 0.8147435897435897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jqCo52hPjkk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "81e5e5d5-2987-4932-cc82-d9cff34d9765"
      },
      "source": [
        "# Plot the results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(min_samples_splits, train_results, 'b')\n",
        "plt.plot(min_samples_splits, val_results,'r')\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EmN0hXcNmys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d144ce19-1101-4c04-8f10-01728ac14fd0"
      },
      "source": [
        "min_samples_splits[np.argmax(val_results)]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrZSntmRYtFL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d8d4a8c-15e1-45a6-e7cc-2b9464da0096"
      },
      "source": [
        "# Choose the best minimum split sample based on the plot\n",
        "Best_minSampl = min_samples_splits[np.argmax(val_results)]\n",
        "\n",
        "# Train decision tree using the full training data and the best minimum split sample\n",
        "best_tree = DecisionTreeClassifier(min_samples_split=Best_minSampl, random_state=2021)\n",
        "best_tree.fit(train_df, train_labels)\n",
        "\n",
        "# Estimate the prediction of the test data\n",
        "test_pred = best_tree.predict(test_df)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Calculate accuracy of test data\n",
        "TestAcc = accuracy_score(test_pred, test_labels)\n",
        "print(\"Testing Accuracy = %.4f%%\" % (TestAcc * 100))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Accuracy = 82.6790%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_GMi20MO3lr"
      },
      "source": [
        "# 6) Apply the same procedure but using k-NN instead of decision tree\n",
        "\n",
        "For finetuning, find the best value of K to use with this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKZoNasEO9BT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "499a94f7-7238-40b8-d7f1-f6c198236c56"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from statistics import mean\n",
        "\n",
        "# initialize the values of k to be a list of odd numbers between 1 and 30\n",
        "kVals = list(range(1, 30, 2))\n",
        "\n",
        "# Save the accuracies of each value of kVal in [accuracies] variable\n",
        "# hint: you can use accuracies.append(...) function inside the loop\n",
        "accuracies = []\n",
        "\n",
        "# loop over values of k for the k-Nearest Neighbor classifier\n",
        "for k in kVals:\n",
        "  # Follow what we did in decision tree part\n",
        "  clf = KNeighborsClassifier(n_neighbors=k)\n",
        "  scores = cross_val_score(clf, train_df, train_labels, cv=5)\n",
        "  accuracies.append(mean(scores))\n",
        "\n",
        "print(\"n_neighbors best:\", kVals[np.argmax(accuracies)])\n",
        "print(\"Best Validation Accuracy = %.4f%%\" % (np.max(accuracies)*100))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_neighbors best: 1\n",
            "Best Validation Accuracy = 81.1854%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1PtA576uw9t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d16baeb-cd5f-46ff-feb4-6fac95d03f62"
      },
      "source": [
        "# Train k-NN using the full training data with the best K that you found\n",
        "best_knn = KNeighborsClassifier(n_neighbors=kVals[np.argmax(accuracies)])\n",
        "best_knn.fit(train_df, train_labels)\n",
        "\n",
        "preds = best_knn.predict(test_df)\n",
        "accuracy = accuracy_score(test_labels, preds)\n",
        "print(accuracy)\n",
        "\n",
        "# Testing"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8329484218629715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBjX29muPFu0"
      },
      "source": [
        "# Report\n",
        "We need to classify wines as good or bad quality according to their given 12 numeric values. We will use decision trees and k-Nearest-Neighbors classifiers.\n",
        "\n",
        "We explored the data by looking at the dataframe's shape, head, and info. There were no categorical features, so we don't need any encoding. We also checked if there are any null values in the dataset, and there were none. As a result, there was no need for preprocessing.\n",
        "\n",
        "We need a validation set for tuning the hyperparameters. We split the training dataset into two random arrays (training set and validation sets) using sci-kit learn's train_test_split method. We have used a random state to create a reproducible output and give test size as 0.3 to have 70% training and 30% validation sets.\n",
        "\n",
        "We have obtained the best results with the Decision Tree classifier with min_samples_splits = 5, giving classification accuracy of 82.679% on test data. We have obtained the best results with the kNN classifier with n_neighbors = 1, giving classification accuracy of 83.294% on test data.\n",
        "\n",
        "kNN needs to scan the dataset every time prediction is required; that's why it was slower than decision tree."
      ]
    }
  ]
}